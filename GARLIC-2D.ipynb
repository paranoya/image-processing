{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6589599",
   "metadata": {},
   "source": [
    "# GARLIC demo\n",
    "\n",
    "General-purpose Adaptive Richardson-Lucy Image Characterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90392ca9-a112-4f16-b177-5ac5fba90f27",
   "metadata": {},
   "source": [
    "# 1. General-purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8729d716-ef67-47bd-9c71-cb12b8077e9e",
   "metadata": {},
   "source": [
    "## Import libraries and scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5629f632",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib ipympl\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy import ndimage, special\n",
    "\n",
    "import importlib\n",
    "import scripts\n",
    "importlib.reload(scripts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbdb640-baa2-4abd-b7c6-6867474162cc",
   "metadata": {},
   "source": [
    "Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757e87c4-3873-4bef-8ca1-4e54fa946622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_figure(fig_name, figsize=(10, 5), nrows=1, ncols=1, sharex='col', sharey='row', gridspec_kw={'hspace': 0, 'wspace': 0}):\n",
    "    plt.close(fig_name)\n",
    "    fig = plt.figure(fig_name, figsize=figsize)\n",
    "    axes = fig.subplots(nrows=nrows, ncols=ncols, squeeze=False,\n",
    "                        sharex=sharex, sharey=sharey,\n",
    "                        gridspec_kw=gridspec_kw\n",
    "                       )\n",
    "    fig.set_tight_layout(True)\n",
    "    for ax in axes.flat:\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.tick_params(which='both', bottom=True, top=True, left=True, right=True)\n",
    "        ax.tick_params(which='major', direction='inout', length=8, grid_alpha=.3)\n",
    "        ax.tick_params(which='minor', direction='in', length=2, grid_alpha=.1)\n",
    "        ax.grid(True, which='both')\n",
    "\n",
    "    fig.suptitle(fig_name)\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a5ed3-8306-4c56-aeb3-5ce57d5c3f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cmap = plt.get_cmap(\"gist_earth\").copy()\n",
    "default_cmap.set_bad('gray')\n",
    "\n",
    "\n",
    "def colour_map(ax, cblabel, data, cmap=default_cmap, norm=None, xlabel=None, x=None, ylabel=None, y=None):\n",
    "    \n",
    "    sigmas = np.linspace(-3, 3, 7)\n",
    "    percentiles = 50 + 50 * special.erf(sigmas / np.sqrt(2))\n",
    "    ticks = np.nanpercentile(data, percentiles)\n",
    "    if norm is None:\n",
    "        if ticks[-1] > 0:\n",
    "            linthresh = np.median(data[data > 0])\n",
    "            norm = colors.SymLogNorm(vmin=ticks[0], vmax=ticks[-1], linthresh=linthresh)\n",
    "        else:\n",
    "            norm = colors.Normalize(vmin=ticks[0], vmax=ticks[-1])\n",
    "\n",
    "    if y is None:\n",
    "        y = np.arange(data.shape[0])\n",
    "    if x is None:\n",
    "        x = np.arange(data.shape[1])\n",
    "\n",
    "    im = ax.imshow(data,\n",
    "                   extent=(x[0]-(x[1]-x[0])/2, x[-1]+(x[-1]-x[-2])/2, y[0]-(y[1]-y[0])/2, y[-1]+(y[-1]-y[-2])/2),\n",
    "                   interpolation='nearest', origin='lower',\n",
    "                   cmap=cmap,\n",
    "                   norm=norm,\n",
    "                  )\n",
    "    #ax.set_aspect('auto')\n",
    "    if xlabel is not None:\n",
    "        ax.set_xlabel(xlabel)\n",
    "    if ylabel is not None:\n",
    "        ax.set_ylabel(ylabel)\n",
    "\n",
    "    cb = fig.colorbar(im, ax=ax, orientation='vertical', shrink=.9)\n",
    "    cb.ax.set_ylabel(cblabel)\n",
    "    if ticks is not None:\n",
    "        cb.ax.set_yticks(ticks=ticks, labels=[f'{value:.3g} ({percent:.1f}%)' for value, percent in zip(ticks, percentiles)])\n",
    "    cb.ax.tick_params(labelsize='small')\n",
    "    \n",
    "    return im, cb, norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5b814b-b558-44cf-9692-7c7cad56fa20",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6af977-8a30-433a-9097-4e679f65e03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scripts.read_data)\n",
    "object_name, data, true_spectrum = scripts.read_data.run(22, (0, 0, 1))\n",
    "data_offset = np.nanmin(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a0f8c-59d9-46f0-ac68-5625db068512",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c0aad-be58-4e8c-8c67-b71c1f15ccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_accuracy = .01\n",
    "max_iter = 100\n",
    "kernel_truncation = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a270ad-0090-4d5e-a8bb-e93a5cb85940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob_threshold = .5\n",
    "peak_threshold = 1.3\n",
    "accretion_threshold = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfaa47c-e709-44b3-b9fe-1fde7be61fd1",
   "metadata": {},
   "source": [
    "# 2. Adaptive Richardson Lucy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c818039-2aa8-497e-a086-6adf06d6a7b2",
   "metadata": {},
   "source": [
    "Find noise, source, and background scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd253f56-3c4e-4597-9e4e-2ad48bd7d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scripts.diffuse_emission)\n",
    "noise_scale = scripts.diffuse_emission.find_scale(data)\n",
    "source_scale = scripts.diffuse_emission.find_scale(ndimage.gaussian_filter(data, noise_scale, truncate=kernel_truncation))\n",
    "diffuse_scale = scripts.diffuse_emission.find_scale(ndimage.gaussian_filter(data, source_scale, truncate=kernel_truncation))\n",
    "print(f'Scales: noise = {noise_scale:.2f}, sources = {source_scale:.2f}, diffuse emission = {diffuse_scale:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e6606c-800a-4d8f-af72-252ac6a09d88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "baseline = np.nanmin(data)\n",
    "print(f'baseline={baseline:4g}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44da7da-0711-478a-91f9-b7a14b716593",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scripts.multiscale_RL)\n",
    "smoothing_radii = np.array([noise_scale, source_scale, diffuse_scale]) / np.sqrt(8*np.log(2)) # FWHM -> Gaussian sigma\n",
    "#smoothing_radii = np.array([noise_scale, source_scale])\n",
    "n_radii = smoothing_radii.size\n",
    "\n",
    "mRL = scripts.multiscale_RL.run(data - baseline, smoothing_radii)\n",
    "RL = np.sum(mRL, axis=0)\n",
    "m_model = np.empty_like(mRL)\n",
    "for i, radius in enumerate(smoothing_radii):\n",
    "    m_model[i] = ndimage.gaussian_filter(mRL[i], radius, truncate=kernel_truncation)\n",
    "model = baseline + np.sum(m_model, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763968ed-78d7-49a8-8464-aa44ea15b848",
   "metadata": {},
   "source": [
    "# 3. Image characterisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e52e41a-455d-4d09-8e12-446851fc47ab",
   "metadata": {},
   "source": [
    "## Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80ed645-5ae0-499b-a628-1389eeda7f69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "residual = data - model\n",
    "noise = np.sqrt(ndimage.gaussian_filter(residual**2, smoothing_radii[0], truncate=kernel_truncation)) #- ndimage.gaussian_filter(residual, diffuse_scale))\n",
    "mean = np.nanmean(noise)\n",
    "noise = np.where(np.isfinite(noise), noise, mean)\n",
    "print(f'noise: {mean:.3g} +- {np.std(noise):.3g} [{np.min(noise):.3g} - {np.max(noise):.3g}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb1cc3d-43e8-42a2-b723-b9e17c117555",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'noise'\n",
    "plt.close(fig_name)\n",
    "fig = plt.figure(fig_name, figsize=(14, 3))\n",
    "axes = fig.subplots(nrows=1, ncols=4, squeeze=False, sharex=True, sharey=True)\n",
    "fig.suptitle(fig_name)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "ax = axes[0, 0]\n",
    "norm = colour_map(ax, 'data', data)[2]\n",
    "\n",
    "ax = axes[0, 1]\n",
    "colour_map(ax, 'model', model, norm=norm)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "#colour_map(ax, 'residual', residual, norm=norm)\n",
    "colour_map(ax, 'residual / noise', residual / noise, cmap='turbo_r', norm=colors.Normalize(vmin=-3, vmax=3))\n",
    "\n",
    "ax = axes[0, 3]\n",
    "#colour_map(ax, 'noise', noise, norm=norm)\n",
    "colour_map(ax, 'noise', noise, cmap='inferno')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610cecfd-db28-4f5d-bba1-53548f0ff7a9",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e951168b-237c-42be-a616-3399b84fd860",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_type = np.argmax(m_model, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e264006-0281-445c-93c3-36c2f8257e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = np.fmin(m_model[-1], mRL[-1])\n",
    "background = ndimage.gaussian_filter(background, smoothing_radii[-1])\n",
    "background = np.nanmedian([m_model[-1], mRL[-1], background], axis=0)\n",
    "background = ndimage.gaussian_filter(background, smoothing_radii[-1])\n",
    "background = baseline + smoothing_radii.size*background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00563b1f-45f6-42ae-a635-59da6408a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = model - background\n",
    "SN = signal / noise\n",
    "median_SN = np.nanmedian(SN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334ea04c-f20d-4042-afad-831e8086dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'signal_and_background'\n",
    "plt.close(fig_name)\n",
    "fig = plt.figure(fig_name, figsize=(8, 5))\n",
    "axes = fig.subplots(nrows=2, ncols=2, squeeze=False, sharex=True, sharey=True)\n",
    "fig.suptitle(fig_name)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "ax = axes[0, 0]\n",
    "norm = colour_map(ax, 'data', data)[2]\n",
    "\n",
    "ax = axes[0, 1]\n",
    "colour_map(ax, 'signal', signal)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "colour_map(ax, 'background', background, norm=norm)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "#colour_map(ax, 'noise', noise, norm=norm)\n",
    "#colour_map(ax, 'noise', noise, cmap='inferno')\n",
    "colour_map(ax, 'S/N', SN, cmap='gnuplot')\n",
    "ax.contour(SN, levels=[peak_threshold], colors=['k'])\n",
    "#ax.contour(SN, levels=[accretion_threshold, peak_threshold], colors=['k', 'k'], linestyles=['-', '--'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaafbaa-e6d0-461b-9532-0c387b6a9050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raise -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af93e1-5e85-4134-92cb-f14685935434",
   "metadata": {},
   "source": [
    "# --- TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f8cb8-4b62-4ca4-bc97-d82892d30a20",
   "metadata": {},
   "source": [
    "## Signal probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2f9db4-6130-4949-91f6-5c47705e4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "mSN = (baseline + 3*m_model - model[np.newaxis, :]) / noise[np.newaxis, :]\n",
    "mp_signal = 1 - np.exp(-.5*mSN**2)\n",
    "#p_signal = 1 - np.sqrt(ndimage.gaussian_filter(np.nanmean((1 - mp_signal)**2, axis=0), source_scale, truncate=kernel_truncation))\n",
    "p_signal = ndimage.gaussian_filter(np.nanmean(mp_signal, axis=0), smoothing_radii[0], truncate=kernel_truncation)\n",
    "#p_signal = np.nanmean(mp_signal, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17457290-f0e2-4b6c-8591-f95bd45a40dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'multi-scale'\n",
    "plt.close(fig_name)\n",
    "fig = plt.figure(fig_name, figsize=(12, 8))\n",
    "axes = fig.subplots(nrows=smoothing_radii.size+1, ncols=4, squeeze=False, sharex=True, sharey=True)\n",
    "fig.suptitle(fig_name)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "def plot_multi(col, thing, cmap=None, norm=None):\n",
    "    lbl = ['compact', 'diffuse', 'background']\n",
    "    for i in range(smoothing_radii.size):\n",
    "        ax = axes[i, col]\n",
    "        colour_map(ax, lbl[i], thing[i], cmap, norm)\n",
    "    colour_map(axes[i+1, col], 'mean', np.nanmean(thing, axis=0), cmap, norm)\n",
    "\n",
    "plot_multi(0, baseline + 3*mRL)\n",
    "plot_multi(1, baseline + 3*m_model)\n",
    "plot_multi(2, mSN, cmap='turbo_r', norm=colors.Normalize(vmin=-3, vmax=3))\n",
    "plot_multi(3, mp_signal, cmap='turbo_r', norm=colors.Normalize(vmin=0, vmax=1))\n",
    "\n",
    "#ax = axes[0, 0]\n",
    "#ax.set_xlim(350, 400)\n",
    "#ax.set_ylim(150, 200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fad7de-97d6-4ec1-abc1-9a75a3f7b6c6",
   "metadata": {},
   "source": [
    "## Background subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec094f9-2384-438b-93ed-2e1af76ffec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "background = baseline + 3*m_model[2]\n",
    "converged = False\n",
    "while not converged:\n",
    "    old_bg = background\n",
    "    background = ndimage.gaussian_filter(np.fmin(background, model), smoothing_radii[-1])\n",
    "    change = (background - old_bg) / noise\n",
    "    a, b = np.min(change), np.max(change)\n",
    "    print(a, b)\n",
    "    if a > -1:\n",
    "        converged = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6cfb38-a4ee-4bae-9611-cff911e9fb73",
   "metadata": {},
   "source": [
    "final_model = p_signal * model + (1 - p_signal) * background = signal + background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea45476-5da7-49f0-818f-818258cdd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = p_signal * (model - background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeeaf51-d90f-4e95-bb4c-b57878ec68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = model - background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d3db6e-b52d-492d-b3f9-4a41f38e2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(data), np.nansum(model), np.nansum(background + signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2d3ee8-d424-45ea-967c-049c21f21f72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "residual = data - (signal + background)\n",
    "noise = np.sqrt(ndimage.gaussian_filter(residual**2, smoothing_radii[0], truncate=kernel_truncation)) #- ndimage.gaussian_filter(residual, background_scale))\n",
    "mean = np.nanmean(noise)\n",
    "noise = np.where(np.isfinite(noise), noise, mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441e1ca-d4a8-4904-80f6-2fc71b929072",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'signal_and_background'\n",
    "plt.close(fig_name)\n",
    "fig = plt.figure(fig_name, figsize=(12, 6))\n",
    "axes = fig.subplots(nrows=2, ncols=3, squeeze=False, sharex=True, sharey=True)\n",
    "fig.suptitle(fig_name)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "ax = axes[0, 0]\n",
    "norm = colour_map(ax, 'data', data)[2]\n",
    "\n",
    "ax = axes[0, 1]\n",
    "colour_map(ax, 'background', background, norm=norm)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "#colour_map(ax, 'noise', noise, norm=norm)\n",
    "colour_map(ax, 'noise', noise, cmap='inferno')\n",
    "\n",
    "\n",
    "ax = axes[1, 0]\n",
    "colour_map(ax, 'signal', signal)\n",
    "ax.contour((p_signal > prob_threshold) & (signal > peak_threshold*noise), levels=[True], colors=['k'])\n",
    "\n",
    "ax = axes[1, 1]\n",
    "colour_map(ax, 'signal probability', p_signal, cmap='seismic_r', norm=colors.Normalize(vmin=0, vmax=1))\n",
    "\n",
    "ax = axes[1, 2]\n",
    "#colour_map(ax, 'signal', model*p_signal + background*(1 - p_signal))\n",
    "colour_map(ax, 'S/N', p_signal*(model-background)/noise, cmap='seismic_r', norm=colors.Normalize(vmin=-2*peak_threshold, vmax=2*peak_threshold))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9998f919-6dcf-4a01-a101-857784dd3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(data), np.sum(model), np.std(noise), np.mean(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b765795-5af2-47ac-a384-70f6c013ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(data-baseline), np.nansum(model-baseline),  np.sum(RL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c454a-ea3f-4945-9ea3-85df97e860b8",
   "metadata": {},
   "source": [
    "# 3. Source finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309db714-4742-41fe-bcc9-5f2cb135205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram((SN_map).ravel(), bins=np.arange(SN_min, SN_max, .1), density=True)\n",
    "x_bins = (bins[1:] + bins[:-1]) / 2\n",
    "index_max = np.argmax(hist)\n",
    "SN_mode = x_bins[index_max]\n",
    "SN_threshold = 2*SN_mode - SN_min\n",
    "'''\n",
    "'''\n",
    ","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf813a-b6e6-4e28-9db1-79332d50bde5",
   "metadata": {},
   "source": [
    "fig, axes = new_figure('residual')\n",
    "\n",
    "\n",
    "ax = axes[0, 0]\n",
    "sc = ax.scatter(residual, baseline + background_estimate, s=1, alpha=.1, c=noise, cmap='jet')\n",
    "cb = fig.colorbar(sc, ax=ax, orientation='vertical', shrink=.9)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68756877-7334-4cdb-bb75-4c396dd72160",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = new_figure('signal-to-noise')#, nrows=2)\n",
    "\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.plot(x_bins, hist, 'k-+')\n",
    "ax.axvline(SN_mode, c='k', ls='--', label=f'mode={SN_mode:.2f}')\n",
    "ax.axvline(SN_threshold, c='k', ls='-.', label=f'mode threshold={SN_threshold:.2f}')\n",
    "ax.axhline(hist[index_max]/2, c='k', ls=':')\n",
    "\n",
    "p16, p50 = np.nanpercentile(SN_map, [16, 50])\n",
    "ax.axvline(p16, c='k', ls=':')\n",
    "ax.axvline(p50, c='c', ls=':', label=f'median={p50:.2f}')\n",
    "ax.axvline(2*p50-SN_min, c='k', ls=':', label=f'median threshold={2*p50-SN_min:.2f}')\n",
    "ax.axvline(SN_mean, c='r', ls='--', label=f'mean={mu0:.2f} +- {std0:.2f}')\n",
    "#ax.axvline(mu0_threshold, c='r', ls='-.', label=f'mu0_threshold={mu0_threshold:.2f}')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "'''\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(residual/noise, background_estimate, s=1, alpha=.1)\n",
    "ax.set_xlim(SN_min, SN_max)\n",
    "'''\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98524e64-ad5d-4ebe-8f0b-b57d74c0bd56",
   "metadata": {},
   "source": [
    "## Hierarchical Overdensity Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c10a2ce-e253-4745-b6b6-623dcad985bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scripts.sort_data)\n",
    "#argsorted_data, n_valid = scripts.sort_data.run(RL.ravel())\n",
    "argsorted_data, n_valid = scripts.sort_data.run(mRL.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f7a62-51a1-4234-bc4c-729eb691a7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scripts.HOT)\n",
    "sorted_strides = np.hstack([np.sort(mRL.strides)//mRL.itemsize, mRL.size]) # DIRTY HACK when testig particles at the boundary\n",
    "t0 = time()\n",
    "HOT_labels, HOT_catalog = scripts.HOT.run(mRL, argsorted_data, sorted_strides)\n",
    "#n_sources = np.unique(HOT_labels).size\n",
    "n_sources = np.max(HOT_labels)\n",
    "print(f'     {time()-t0:.3g} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549bab15-02e4-480a-a490-cacde21635f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOT_parent = HOT_catalog[0]\n",
    "'''\n",
    "HOT_area = HOT_catalog[1]\n",
    "HOT_test_stat = HOT_catalog[2]\n",
    "HOT_bg = HOT_catalog[3]\n",
    "#max_test_stat = catalog[3]\n",
    "'''\n",
    ","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae14ea2-ad07-4b52-98c2-18888c20183f",
   "metadata": {},
   "source": [
    "## Individual sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa9b19d-c37a-4eeb-bb89-f77b2ad85142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_source_model(mRL, HOT_labels, lbl):\n",
    "    RL = np.zeros_like(data)\n",
    "    indices = np.where(HOT_labels[0] == lbl)\n",
    "    RL[indices] = mRL[0][indices]\n",
    "    source_model = ndimage.gaussian_filter(RL, smoothing_radii[0])\n",
    "    \n",
    "    RL = np.zeros_like(data)\n",
    "    indices = np.where(HOT_labels[1] == lbl)\n",
    "    RL[indices] = mRL[1][indices]\n",
    "    source_model += ndimage.gaussian_filter(RL, smoothing_radii[1])\n",
    "    \n",
    "    return source_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc2857c-1c34-4a38-b2ca-7d0765649aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_moment(m):\n",
    "    RL_moment = mRL.copy()\n",
    "    for i, radius in enumerate(smoothing_radii):\n",
    "        RL_moment[i] *= ndimage.gaussian_filter(residual**m / (compact_emission + diffuse_emission), radius)\n",
    "    moment = np.zeros(n_sources+1)\n",
    "    np.add.at(moment, HOT_labels, RL_moment)\n",
    "    return moment\n",
    "\n",
    "source_area = compute_moment(0)\n",
    "source_residual = compute_moment(1)\n",
    "mean_residual = source_residual / source_area\n",
    "#rms_residual = compute_moment(2) / source_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c6145-edef-4e02-814f-f3725054d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_SN = mean_residual * np.sqrt(source_area) / noise\n",
    "sorted_by_SN = np.argsort(source_SN)\n",
    "n_fluke = np.count_nonzero(np.cumsum(source_residual[sorted_by_SN]) < 0)\n",
    "SN_threshold = source_SN[sorted_by_SN[n_fluke]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb0a8d7-e2a3-42a0-b4ae-8ef911569dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_source = (source_SN > SN_threshold) & (source_area > compact_scale)\n",
    "n_true = np.count_nonzero(true_source)\n",
    "print(f'{n_true} true sourcces above S/N={SN_threshold:.1f} and area={compact_scale:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee57ee4-5ae6-4683-bdc6-4c79c212faba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = new_figure('source_flux', nrows=1, figsize=(12, 8))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.axhline(SN_threshold, color='k', ls=':', label=f'{SN_threshold:.2f} x {noise:.3g} = {SN_threshold*noise:.3g}')\n",
    "ax.axvline(compact_scale, color='k', ls='--', label=f'compact scale = {compact_scale:.3g}')\n",
    "ax.axvline(diffuse_scale, color='k', ls=':', label=f'diffuse scale = {diffuse_scale:.3g}')\n",
    "\n",
    "ax.scatter(source_area[true_source], source_SN[true_source], c='b', s=.1, alpha=1)\n",
    "ax.scatter(source_area[~true_source], source_SN[~true_source], c='r', s=.1, alpha=.5)\n",
    "#for i in range(n_sources+1):\n",
    "#    ax.text(source_residual[i], mean_residual[i], i, fontsize='x-small', clip_on=True)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65304c39-05ca-4cd8-ab94-7d7a999dac75",
   "metadata": {},
   "source": [
    "# 3. Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9601e96-aced-431b-9caf-d15a0fef64e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Normalisation and color maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f86764-f359-44b2-b45c-ddd3f9ea7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sources = np.unique(HOT_labels).size\n",
    "latin_cube = np.vstack([(np.argsort(np.random.random(n_sources))+1)/n_sources, (np.argsort(np.random.random(n_sources))+1)/n_sources, (np.argsort(np.random.random(n_sources))+1)/n_sources, np.ones(n_sources)]).T\n",
    "latin_cube[0, :] = [0., 0., 0., 1.]  # background object must be black :^)\n",
    "label_cmap = colors.ListedColormap(latin_cube)\n",
    "label_norm = colors.Normalize(vmin=-.5, vmax=n_sources+.5)\n",
    "print(f'{n_sources} unique sourcces')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc23e9c-ecf4-4ef1-95d4-e2aa25d15e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mRL_cmap = default_cmap\n",
    "mRL_norm = colors.LogNorm(vmin=np.percentile(mRL[mRL>0], 10), vmax=np.percentile(mRL[mRL>0], 99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0449bf-8eaa-4781-904d-e796e7823791",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_name = 'GARLIC_test'\n",
    "plt.close(fig_name)\n",
    "fig = plt.figure(fig_name, figsize=(15, 6))\n",
    "axes = fig.subplots(nrows=2, ncols=4, squeeze=False, sharex=True, sharey=True)\n",
    "fig.suptitle(fig_name)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "combined_labels = HOT_labels[0].copy()\n",
    "flukes = np.where(~true_source[combined_labels])\n",
    "combined_labels[flukes] = HOT_labels[1][flukes]\n",
    "flukes = np.where(~true_source[combined_labels])\n",
    "combined_labels[flukes] = 0\n",
    "\n",
    "ax = axes[0, 0]\n",
    "colour_map(ax, 'compact', HOT_labels[0], cmap=label_cmap, norm=label_norm)\n",
    "ax = axes[0, 1]\n",
    "colour_map(ax, 'diffuse', HOT_labels[1], cmap=label_cmap, norm=label_norm)\n",
    "ax = axes[0, 2]\n",
    "colour_map(ax, 'combined', combined_labels, cmap=label_cmap, norm=label_norm)\n",
    "ax = axes[0, 3]\n",
    "colour_map(ax, 'data', data)\n",
    "\n",
    "metric = source_SN\n",
    "ax = axes[1, 0]\n",
    "colour_map(ax, 'compact', metric[HOT_labels[0]])\n",
    "ax = axes[1, 1]\n",
    "colour_map(ax, 'diffuse', metric[HOT_labels[1]])\n",
    "ax = axes[1, 2]\n",
    "colour_map(ax, 'combined', metric[combined_labels])\n",
    "ax = axes[1, 3]\n",
    "colour_map(ax, 'residual', residual)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6f3f10-50a6-4f69-b924-8172e09882b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(true_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1eb6a-5bb5-4bb6-b9da-e191d4467437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mRL_inpaint(mRL, labels, target):\n",
    "\n",
    "    mRL_target = np.zeros_like(mRL)\n",
    "    indices = np.where(labels == target)\n",
    "    mRL_target[indices] = mRL[indices]\n",
    "\n",
    "    radius = np.sqrt(mRL.shape[0])\n",
    "    inpaint_map = np.where(mRL_target > 0, 1., 0.)  # object mask\n",
    "    inpaint_map = ndimage.gaussian_filter(inpaint_map, radius)  # interpolation weight\n",
    "    inpaint_map = np.clip(inpaint_map, np.min(inpaint_map[inpaint_map > 0]), np.inf)  # to prevent division by zero\n",
    "    inpaint_map = ndimage.gaussian_filter(mRL_target, radius) / inpaint_map\n",
    "\n",
    "    return mRL_target, np.fmin(inpaint_map, mRL)\n",
    "\n",
    "\n",
    "def get_individual_mRL(mRL, labels, parent, target):\n",
    "\n",
    "    mRL_target, inpaint_map = get_mRL_inpaint(mRL, labels, target)\n",
    "    \n",
    "    # compute contribution to descendants:\n",
    "    progenitor = parent[labels]\n",
    "    if parent[target] == target:\n",
    "        indices = np.where(labels == target)\n",
    "        progenitor[indices] = 0\n",
    "    n_found = 1\n",
    "    while n_found > 0:\n",
    "        indices = np.where(progenitor == target)\n",
    "        n_found = len(indices[0])\n",
    "        #print(f'{n_found} values painted')\n",
    "        mRL_target[indices] = inpaint_map[indices]\n",
    "        if parent[target] == target:\n",
    "            progenitor[indices] = 0\n",
    "        progenitor = parent[progenitor]\n",
    "\n",
    "    # remove contribution from ancestors:\n",
    "    '''\n",
    "    RL[target] = mRL[target] - bg[lbl]\n",
    "    '''\n",
    "\n",
    "    return mRL_target\n",
    "\n",
    "\n",
    "class Explore_lbl_1D(object):\n",
    "    \n",
    "    def __init__(self, fig_name, data, boosted_data, estimate, label, parent):\n",
    "        \"\"\"Interactive display\"\"\"\n",
    "        \n",
    "        plt.close(fig_name)\n",
    "        self.fig = plt.figure(fig_name, figsize=(12, 7))\n",
    "        self.axes = self.fig.subplots(nrows=4, ncols=2, squeeze=False, sharex='col', gridspec_kw={'width_ratios': [1, .02], 'hspace': 0})\n",
    "        self.fig.suptitle(fig_name)\n",
    "        self.fig.set_tight_layout(True)\n",
    "\n",
    "        self.original = data\n",
    "        self.boosted_data = boosted_data\n",
    "        self.data_offset = np.nanmin(data)\n",
    "        #self.RL = RL\n",
    "        #self.SSF = SSF\n",
    "        self.total_estimate = estimate\n",
    "        self.label = label\n",
    "        self.parent = parent\n",
    "\n",
    "        self.ax_parent = self.axes[0, 0]\n",
    "        self.ax_parent_cb = self.axes[0, 1]\n",
    "        self.ax_lbl = self.axes[1, 0]\n",
    "        self.ax_lbl_cb = self.axes[1, 1]\n",
    "\n",
    "        self.ax_im = self.axes[2, 0]\n",
    "        self.ax_cb = self.axes[2, 1]\n",
    "\n",
    "        self.ax0 = self.axes[3, 0]\n",
    "        self.ax0.plot(data, 'k-', alpha=.2)\n",
    "        self.ax0.set_xlim(0, data.size)\n",
    "        self.axes[3, 1].axis('off')\n",
    "\n",
    "        self.widget = widgets.interactive(self.plot_lbl, lbl=widgets.BoundedIntText(value=1, min=1, max=n_sources, continuous_update=False))\n",
    "        display(self.widget)\n",
    "\n",
    "\n",
    "    def plot_lbl(self, lbl):\n",
    "        xlim = self.ax0.get_xlim()\n",
    "        ylim = self.ax0.get_ylim()\n",
    "\n",
    "        ax = self.ax_parent\n",
    "        im = ax.imshow(self.parent[self.label],\n",
    "                       interpolation='nearest', origin='lower',\n",
    "                       cmap=label_cmap, norm=colors.Normalize(vmin=-.5, vmax=n_sources+.5),\n",
    "                      )\n",
    "        ax.set_aspect('auto')\n",
    "        #ax.set_ylim(-1, n_radii+1)\n",
    "        ticks = np.array(ax.get_yticks(), dtype=int)#.clip(0, n_radii-1)\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels([f'{radius:.3g}' for radius in smoothing_radii[ticks]])\n",
    "        cb = plt.colorbar(im, cax=self.ax_parent_cb, orientation='vertical', shrink=.9)\n",
    "        cb.ax.tick_params(labelsize='small')\n",
    "        cb.ax.set_ylabel('parent ID')\n",
    "        \n",
    "        \n",
    "        ax = self.ax_lbl\n",
    "        im = ax.imshow(self.label,\n",
    "                       interpolation='nearest', origin='lower',\n",
    "                       cmap=label_cmap, norm=colors.Normalize(vmin=-.5, vmax=n_sources+.5),\n",
    "                      )\n",
    "        ax.set_aspect('auto')\n",
    "        #ax.set_ylim(-1, n_radii+1)\n",
    "        ticks = np.array(ax.get_yticks(), dtype=int)#.clip(0, n_radii-1)\n",
    "        ax.set_yticks(ticks)\n",
    "        ax.set_yticklabels([f'{radius:.3g}' for radius in smoothing_radii[ticks]])\n",
    "        cb = plt.colorbar(im, cax=self.ax_lbl_cb, orientation='vertical', shrink=.9)\n",
    "        cb.ax.tick_params(labelsize='small')\n",
    "        cb.ax.set_ylabel('source ID')\n",
    "\n",
    "        \n",
    "        RL = get_individual_mRL(mRL, HOT_labels, HOT_parent, lbl)\n",
    "        self.ax_im.clear()\n",
    "        im = self.ax_im.imshow(RL,\n",
    "                               interpolation='nearest', origin='lower',\n",
    "                               #cmap='gist_earth', norm=colors.LogNorm(vmin=np.min(RL[RL > 1e3*epsilon])))\n",
    "                               #cmap=default_cmap, norm=colors.LogNorm(vmin=1/n_radii),\n",
    "                               cmap=default_cmap, norm=colors.LogNorm(vmin=np.percentile(mRL[mRL>0], 10), vmax=np.percentile(mRL[mRL>0], 99)),\n",
    "                               #cmap=default_cmap, norm=colors.LogNorm(vmin=np.percentile(RL[RL>0], 1), vmax=np.percentile(RL[RL>0], 99)),\n",
    "                              )\n",
    "        self.ax_im.set_aspect('auto')\n",
    "        cb = plt.colorbar(im, cax=self.ax_cb, orientation='vertical', shrink=.9)\n",
    "        cb.ax.tick_params(labelsize='small')\n",
    "        self.fig.canvas.draw_idle()\n",
    "        \n",
    "\n",
    "        ax = self.ax0\n",
    "        ax.clear()\n",
    "\n",
    "        #RL = RL[np.newaxis, :] * self.SSF[:, np.newaxis]\n",
    "        estimate = np.empty_like(RL)\n",
    "        for i, radius in enumerate(smoothing_radii):\n",
    "            #self.ax0.plot(original_pixel, RL[i], 'k-', alpha=.1)\n",
    "            estimate[i] = ndimage.gaussian_filter(RL[i], radius)\n",
    "        estimate = np.sum(estimate, axis=0)\n",
    "        #print(np.min(estimate))\n",
    "        \n",
    "        fraction = estimate/self.total_estimate\n",
    "        #estimate_data_offset = np.sum(estimate * ((self.boosted_data+self.data_offset)*fraction - estimate)) / np.sum(estimate)\n",
    "        final_estimate = estimate #+ estimate_data_offset*np.sqrt(fraction/np.max(fraction))\n",
    "        #print(estimate_data_offset, np.max(fraction))\n",
    "        #estimate = self.boosted_data*fraction + self.data_offset*np.mean(fraction)\n",
    "        #print(f'area: {np.sum(fraction):.2f} ({area[lbl]}),',\n",
    "        #      f'flux: {np.nansum(final_estimate):.2f} ({test_stat[lbl]:.2f}),',\n",
    "        mu = np.nansum(final_estimate) / np.count_nonzero(final_estimate > 0)\n",
    "        print(f'area: {np.sum(fraction):.2f} ({np.count_nonzero(final_estimate[final_estimate <= mu] > 0)} + {np.count_nonzero(final_estimate[final_estimate > mu] > 0)} = {np.count_nonzero(final_estimate > 0)}),',\n",
    "              f'flux: {np.nansum(final_estimate):.2f} ({np.nansum(final_estimate[final_estimate <= mu]):.2f}, {np.nansum(final_estimate[final_estimate > mu]):.2f}),',\n",
    "              f'min-max:{np.min(self.boosted_data*fraction):.2f}-{np.max(self.boosted_data*fraction):.2f},'\n",
    "              f'mean:{mu:.3f}',\n",
    "              f'rms:{np.sum((fraction*self.boosted_data)**2)/np.sum(self.boosted_data*fraction):.3f}')\n",
    "        print()\n",
    "\n",
    "        #ax.plot(original_pixel, (self.boosted_data+self.data_offset)*fraction, 'r-.', alpha=.5)\n",
    "\n",
    "        ax.plot(self.original, 'k-', alpha=.3)\n",
    "        ax.plot(self.total_estimate + baseline, 'b-', alpha=.25)\n",
    "        #ax.axhline(data_offset, c='r', ls=':', alpha=.5)\n",
    "        ax.plot(baseline, 'y-', alpha=.5)\n",
    "        ax.plot(baseline + residual_above_bg, 'y:', alpha=.5)\n",
    "        ax.fill_between(np.arange(data.size), baseline, baseline+2*residual_above_bg, color='y', alpha=.1)\n",
    "\n",
    "        ax.plot(np.sum(RL, axis=0) + baseline, 'r-', alpha=.25)\n",
    "        ax.plot(estimate + baseline, 'g-', alpha=.5)\n",
    "\n",
    "\n",
    "        ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "        ax.tick_params(which='both', bottom=True, top=True, left=True, right=True)\n",
    "        ax.tick_params(which='major', direction='inout', length=8, grid_alpha=.3)\n",
    "        ax.tick_params(which='minor', direction='in', length=2, grid_alpha=.1)\n",
    "        ax.grid(True, which='both')\n",
    "        #ax.set_yscale('log')\n",
    "        ax.set_ylim(.9*self.data_offset, 3e5)\n",
    "        ax.set_xlim(xlim)\n",
    "        ax.set_ylim(ylim)\n",
    "        #self.ax0.set_xlim(5000, 5300)\n",
    "\n",
    "\n",
    "if len(data.shape) == 1:\n",
    "    estimate = np.empty_like(mRL)\n",
    "    for i, radius in enumerate(smoothing_radii):\n",
    "        estimate[i] = ndimage.gaussian_filter(mRL[i], radius)\n",
    "    estimate = np.sum(estimate, axis=0)\n",
    "    rms_residual = np.std(boosted_sources - estimate)\n",
    "\n",
    "    #for i, radius in enumerate(smoothing_radii):\n",
    "    #     mRL[i] *= ndimage.gaussian_filter((boosted_data+epsilon) / (estimate+epsilon), radius)\n",
    "    #RL = np.nansum(mRL, axis=0)\n",
    "    #SSF_amplitude = np.nanmedian(mRL/RL[np.newaxis, :], axis=1)\n",
    "    #print(rms_residual)\n",
    "    x = Explore_lbl_1D(object_name, data, boosted_sources, estimate, HOT_labels, HOT_parent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785cad69-f3ec-4d3a-aae9-f2be9c8751d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_above_bg, residual_above_bg*data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d4849-65c9-4b57-85b1-4bcaa63ec44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nansum(data-baseline), np.sqrt(np.nanstd(data-baseline-estimate)), np.nanmean(data-baseline-estimate), np.nanmedian(data-baseline-estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bad1e4-e12c-4fff-aa2a-6c7604e0f5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(data-baseline), np.nanmean(data-baseline), np.nanstd(data-baseline-estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793f554-5085-490c-9d75-7ac2ec20b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nanmedian(estimate), np.nanmean(estimate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ddc7ce-701a-47cf-874b-2f841a8de8db",
   "metadata": {},
   "source": [
    "# --- OLD STUFF ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbc8882-95f7-44d0-b40e-49ab759581a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "fig_name = 'bg_test'\n",
    "plt.close(fig_name)\n",
    "fig = plt.figure(fig_name, figsize=(12,4))\n",
    "axes = fig.subplots(nrows=1, ncols=1, squeeze=False)\n",
    "fig.suptitle(fig_name)\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "\n",
    "ax = axes[0, 0]\n",
    "ax.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "ax.tick_params(which='both', bottom=True, top=True, left=True, right=True)\n",
    "ax.tick_params(which='major', direction='inout', length=8, grid_alpha=.3)\n",
    "ax.tick_params(which='minor', direction='in', length=2, grid_alpha=.1)\n",
    "ax.grid(True, which='both')\n",
    "\n",
    "ax.plot(true_spectrum, 'g-', alpha=.3)\n",
    "ax.plot(data, 'k-', alpha=.2)\n",
    "#ax.axhline(data_offset, c='r', ls=':', alpha=.5)\n",
    "ax.plot(baseline, 'y-', alpha=.5)\n",
    "ax.plot(baseline + residual_above_bg, 'y:', alpha=.5)\n",
    "ax.fill_between(np.arange(data.size), baseline, baseline+2*residual_above_bg, color='y', alpha=.1)\n",
    "\n",
    "\n",
    "ax.set_xlabel('pixel')\n",
    "#ax.set_xlim(5900, 6300)\n",
    "ax.set_ylim(np.min(baseline-residual_above_bg), np.max(baseline+4*residual_above_bg)*1.1)\n",
    "\n",
    "plt.show()\n",
    "'''\n",
    ","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b22a588-c824-4c5c-8832-6cd0c083224c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c6d0a-ba9e-4608-8069-4200f60c7b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(scripts.multiscale_RL)\n",
    "\n",
    "compact_scale, diffuse_scale, baseline, residual_above_bg = scripts.diffuse_emission.run(data, max_iter=14)\n",
    "smoothing_radii = np.array([1, compact_scale, diffuse_scale])\n",
    "n_radii = smoothing_radii.size\n",
    "\n",
    "n_iter = 0\n",
    "mean_residual = 1\n",
    "mean_below = 0\n",
    "diffuse_emission = baseline\n",
    "while n_iter < 10 and mean_residual > mean_below:\n",
    "    n_iter += 1\n",
    "    boosted_sources, mRL = scripts.multiscale_RL.run((data - diffuse_emission).clip(min=0), smoothing_radii)\n",
    "    compact_emission = ndimage.gaussian_filter(mRL[0], 1) + ndimage.gaussian_filter(mRL[1], compact_scale)\n",
    "    diffuse_residual = ndimage.gaussian_filter(mRL[2], diffuse_scale)\n",
    "    total = np.nansum(data - baseline)\n",
    "    mean_residual = np.nanmean(diffuse_residual)\n",
    "    mean_below = np.nanmean((baseline - data)[data < diffuse_emission])\n",
    "    print(np.nansum(compact_emission)/total, mean_residual, mean_below)\n",
    "    diffuse_emission += diffuse_residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67f0423-ce10-460c-bc2c-115a3d8f78a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "importlib.reload(scripts.diffuse_emission)\n",
    "compact_scale, diffuse_scale, baseline, residual_above_bg = scripts.diffuse_emission.run(data, max_iter=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000648bc-2b6d-4e62-bdea-6b29fe0f969d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#smoothing_radii = np.array([1, np.sqrt(compact_scale), compact_scale])\n",
    "smoothing_radii = np.array([1, compact_scale, diffuse_scale])\n",
    "n_radii = smoothing_radii.size\n",
    "importlib.reload(scripts.multiscale_RL)\n",
    "boosted_sources, mRL = scripts.multiscale_RL.run((data-baseline).clip(min=0), smoothing_radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbed78c0-a762-4c99-825a-07ec8d1a429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline += ndimage.gaussian_filter(mRL[2], diffuse_scale)\n",
    "boosted_sources, mRL = scripts.multiscale_RL.run((data-baseline).clip(min=0), smoothing_radii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb302fe5-31c6-4043-b70e-97cfeb7bd876",
   "metadata": {},
   "outputs": [],
   "source": [
    "compact_emission = ndimage.gaussian_filter(mRL[0], 1) + ndimage.gaussian_filter(mRL[1], compact_scale)\n",
    "diffuse_residual = ndimage.gaussian_filter(mRL[2], diffuse_scale)\n",
    "estimate = baseline + np.sum(mRL, axis=0)\n",
    "#index_minima = np.where(estimate < baseline + diffuse_residual + compact_emission)\n",
    "#index_minima = scripts.diffuse_emission.find_minima(compact_emission)\n",
    "index_minima = scripts.diffuse_emission.find_minima(estimate)\n",
    "\n",
    "minima = estimate[index_minima] - baseline[index_minima]\n",
    "p16, p50 = np.nanpercentile(minima, [16, 50])\n",
    "mu0 = p50\n",
    "var0 = (p50 - p16)**2\n",
    "weight = np.exp(-.5 * (minima - mu0)**2 / var0)\n",
    "total_weight = np.nansum(weight)\n",
    "mu1 = np.nansum(weight * minima) / total_weight\n",
    "var1 = np.nansum(weight * (minima- mu1)**2) / total_weight\n",
    "var = 1 / (1/var1 - 1/var0)\n",
    "mu = var * (mu1/var1 - mu0/var0)\n",
    "diffuse_offset = mu\n",
    "print(diffuse_offset, np.sqrt(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb27962-6687-4599-9747-b10bd6dc26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse_weight = (diffuse_residual / np.nansum(diffuse_residual)) / (compact_emission / np.nansum(compact_emission))\n",
    "y = diffuse_weight * (data - baseline)\n",
    "mu = np.nansum(y) / np.sum(diffuse_weight[np.isfinite(y)])\n",
    "mu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc14b71-d53e-4d67-90e7-4dccec4592d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse_residual_norm = mu / np.nanmean(diffuse_residual)\n",
    "diffuse_emission = baseline + diffuse_residual_norm*diffuse_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b766572-1bc5-4af8-b984-c5caa9338e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse_residual_norm = mu / np.nanmean(mRL[2][index_minima])\n",
    "diffuse_emission = baseline + diffuse_residual_norm*diffuse_residual\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
